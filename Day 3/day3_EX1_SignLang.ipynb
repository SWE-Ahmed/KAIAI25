{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "qWb17ZPBAWvP"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Arabic Sign Language Recognition using a Neural Network\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This notebook details the implementation of a neural network using PyTorch to recognize Arabic Sign Language alphabets.  The goal is to contribute to improving accessibility and communication for those who use sign language.\n",
        "\n",
        "## 1. Dataset Details: ArASL\n",
        "\n",
        "This project utilizes the ArASL (Arabic Alphabets Sign Language Dataset).  This dataset contains images of hand signs representing the Arabic alphabet.\n",
        "\n",
        "- **Total Images:** 54,049\n",
        "- **Classes:** 32 (representing the Arabic alphabet)\n",
        "\n",
        "## 2. Dataset Split\n",
        "\n",
        "The dataset has been split into training and validation sets:\n",
        "\n",
        "- **Training Set Size:** 43,239 images\n",
        "- **Validation Set Size:** 10,810 images\n",
        "\n",
        "## 3. Label Representation\n",
        "\n",
        "Each image is associated with a numerical label representing a specific Arabic character.  These labels are integers ranging from 0 to 31.\n",
        "\n",
        "## 4. Character Mapping\n",
        "\n",
        "The mapping between numerical labels and corresponding Arabic characters is defined in the `mapping` variable (see code).  The mapping is also provided below for reference:\n",
        "\n",
        "0: 'seen', 1: 'zay', 2: 'aleff', 3: 'dal', 4: 'ta', 5: 'yaa', 6: 'fa', 7: 'ya', 8: 'khaa', 9: 'nun', 10: 'ha', 11: 'toot', 12: 'taa', 13: 'ra', 14: 'kaaf', 15: 'jeem', 16: 'laam', 17: 'la', 18: 'dhad', 19: 'dha', 20: 'waw', 21: 'meem', 22: 'al', 23: 'sheen', 24: 'haa', 25: 'thaa', 26: 'saad', 27: 'ghain', 28: 'ain', 29: 'thal', 30: 'gaaf', 31: 'bb'\n",
        "\n",
        "## 5. Reference\n",
        "\n",
        "Latif, G., Mohammad, N., Alghazo, J., AlKhalaf, R., & AlKhalaf, R. (2019). ARASL: Arabic Alphabets Sign Language Dataset. *Data in Brief*, 23, 103777. https://doi.org/10.1016/j.dib.2019.103777"
      ],
      "metadata": {
        "id": "PrjZIlXJPDHo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BCpQaqwoH2Pk"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the required libraries (needed when running outside colab where the environment doesn't come pre-loaded with libraries)\n",
        "\n",
        "%pip install torch\n",
        "%pip install torchvision\n",
        "%pip install matplotlib\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "HBuuF9MJKjoe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms.functional import to_tensor, to_pil_image, resize\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "gtV7omCIKq0K"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading the dataset\n",
        "\n",
        "### Run the following cells to download the MNIST dataset."
      ],
      "metadata": {
        "id": "Gw5z1ZSoLlh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://data.mendeley.com/public-files/datasets/y7pckrw6z2/files/1efa0d6b-4d7f-4f58-9584-08f0488279ee/file_downloaded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqQxPwbp7TfV",
        "outputId": "01bdc7b5-f833-4a4b-a7b6-ec64582d45fe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://data.mendeley.com/public-files/datasets/y7pckrw6z2/files/1efa0d6b-4d7f-4f58-9584-08f0488279ee/file_downloaded\n",
            "To: /content/file_downloaded\n",
            "100% 66.2M/66.2M [00:02<00:00, 25.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def delete_folder(folder_path):\n",
        "    try:\n",
        "        # Get the list of files and subdirectories in the folder\n",
        "        for item in os.listdir(folder_path):\n",
        "            item_path = os.path.join(folder_path, item)\n",
        "\n",
        "            # If it's a file, delete it\n",
        "            if os.path.isfile(item_path):\n",
        "                os.remove(item_path)\n",
        "            # If it's a directory, recursively call delete_folder\n",
        "            elif os.path.isdir(item_path):\n",
        "                delete_folder(item_path)\n",
        "\n",
        "        # Remove the empty folder\n",
        "        os.rmdir(folder_path)\n",
        "        print(f\"Folder '{folder_path}' and its contents deleted successfully.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Folder '{folder_path}' not found.\")\n",
        "    except PermissionError:\n",
        "        print(f\"Permission error: Unable to delete folder '{folder_path}'.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "\n",
        "delete_folder('ArASL_Database_54K_Final')\n",
        "\n",
        "!unzip file_downloaded\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "yfnx8Ebf7pTT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### If you will build the neural network using numpy, change `t`'s value to 28. If you will build the neural network using pytorch, change `t`'s vlaue to 48. `t`'s value represents the size of the image."
      ],
      "metadata": {
        "id": "HmgvoOHCQ47Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = 48"
      ],
      "metadata": {
        "id": "y-haxexuQ1ZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Just run these two cells. You are not supposed to explore them."
      ],
      "metadata": {
        "id": "qWb17ZPBAWvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def rename_folders_and_create_mapping(folder_path):\n",
        "    # Get the list of folders in the specified path\n",
        "    folders = [folder for folder in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, folder))]\n",
        "\n",
        "    # Create a mapping from original folder names to numbers\n",
        "    folder_mapping = {folder: i for i, folder in enumerate(folders)}\n",
        "\n",
        "    # Rename the folders in-place and store the original names in the mapping\n",
        "    for original_folder, number in folder_mapping.items():\n",
        "        new_folder_name = str(number)\n",
        "        new_folder_path = os.path.join(folder_path, new_folder_name)\n",
        "\n",
        "        # Rename the folder\n",
        "        os.rename(os.path.join(folder_path, original_folder), new_folder_path)\n",
        "\n",
        "    return folder_mapping\n",
        "\n",
        "folder_path = 'ArASL_Database_54K_Final'\n",
        "\n",
        "# Create the folder mapping and rename folders\n",
        "mapping = rename_folders_and_create_mapping(folder_path)\n",
        "\n",
        "# Print the folder mapping\n",
        "print(\"Folder Mapping:\")\n",
        "print(mapping)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sjyA1C1E5ik",
        "outputId": "3c8b20f6-571f-4fc3-93ce-0e0406b66337"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder Mapping:\n",
            "{'taa': 0, 'la': 1, 'ya': 2, 'yaa': 3, 'ghain': 4, 'ta': 5, 'kaaf': 6, 'dal': 7, 'bb': 8, 'ra': 9, 'waw': 10, 'laam': 11, 'thal': 12, 'fa': 13, 'seen': 14, 'khaa': 15, 'zay': 16, 'nun': 17, 'meem': 18, 'dhad': 19, 'ain': 20, 'sheen': 21, 'toot': 22, 'jeem': 23, 'ha': 24, 'al': 25, 'thaa': 26, 'gaaf': 27, 'saad': 28, 'dha': 29, 'haa': 30, 'aleff': 31}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_folder, transform=None, target_size=(28, 28)):\n",
        "        self.root_folder = root_folder\n",
        "        self.transform = transform\n",
        "        self.target_size = target_size\n",
        "\n",
        "        # Get the list of image files\n",
        "        self.image_files = []\n",
        "        self.image_labels = []\n",
        "\n",
        "        for root, dirs, files in os.walk(root_folder):\n",
        "            for file in files:\n",
        "                if file.lower().endswith('.jpg'):\n",
        "                    self.image_files.append(os.path.join(root, file))\n",
        "                    self.image_labels.append(int(os.path.basename(root)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_files[idx]\n",
        "        label = self.image_labels[idx]\n",
        "\n",
        "        # Convert label to tensor\n",
        "        # print(\"Label\", label, type(label))\n",
        "        label = torch.tensor(label)\n",
        "\n",
        "        # Open the image\n",
        "        with Image.open(img_path) as img:\n",
        "            # Convert the image to grayscale\n",
        "            img = img.convert('L')\n",
        "\n",
        "            # Resize the image\n",
        "            img = img.resize(self.target_size)\n",
        "\n",
        "            # Apply additional transformations if specified\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "\n",
        "            return (img, label)\n",
        "\n",
        "# Define the root folder and output folder\n",
        "root_folder_path = 'ArASL_Database_54K_Final'\n",
        "\n",
        "\n",
        "# Define transformations (resize to 28x28 and convert to tensor)\n",
        "data_transform = transforms.Compose([\n",
        "\n",
        "    transforms.Resize((t, t)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Create an instance of the custom dataset\n",
        "custom_dataset = CustomDataset(root_folder_path, transform=data_transform)\n",
        "\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "# Define the size of the training and validation sets\n",
        "total_size = len(custom_dataset)\n",
        "train_size = int(0.8 * total_size)  # 80% for training\n",
        "val_size = total_size - train_size  # 20% for validation\n",
        "\n",
        "# Split the dataset\n",
        "train_dataset, val_dataset = random_split(custom_dataset, [train_size, val_size])\n",
        "\n",
        "mapping = {v:k for k,v in mapping.items()}"
      ],
      "metadata": {
        "id": "Efxefg5j94pO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring the data"
      ],
      "metadata": {
        "id": "ObDvaInfAdBJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Here is the mapping for each class and its encoding. In addition to the train_dataset and val_dataset"
      ],
      "metadata": {
        "id": "GmA6buxlh9XI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset # Contains the training ArASL_Database_54K_Final dataset (80%)\n",
        "\n",
        "val_dataset  # Contains the validating ArASL_Database_54K_Final dataset (20%)\n",
        "\n",
        "\n",
        "print(\"The mapping between the letters and the encoding: \\n\", mapping)\n",
        "\n",
        "# Check the lengths of train_dataset and val_dataset.\n",
        "len(train_dataset), len(val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60ugrf0DMF2N",
        "outputId": "1c5fd5fa-baa1-4eaa-fd11-bdbc233a6155"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The mapping between the letters and the encoding: \n",
            " {0: 'taa', 1: 'la', 2: 'ya', 3: 'yaa', 4: 'ghain', 5: 'ta', 6: 'kaaf', 7: 'dal', 8: 'bb', 9: 'ra', 10: 'waw', 11: 'laam', 12: 'thal', 13: 'fa', 14: 'seen', 15: 'khaa', 16: 'zay', 17: 'nun', 18: 'meem', 19: 'dhad', 20: 'ain', 21: 'sheen', 22: 'toot', 23: 'jeem', 24: 'ha', 25: 'al', 26: 'thaa', 27: 'gaaf', 28: 'saad', 29: 'dha', 30: 'haa', 31: 'aleff'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43239, 10810)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# DataLoaders simplify the job of grouping the samples into batches.\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)  # Do Not shuffle validation data"
      ],
      "metadata": {
        "id": "Oj4XUGKBQmwH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_loader))[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3u-50-1Qgq2",
        "outputId": "ad9edcbf-d209-48e5-9e57-3e4eb21d397c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 1, 48, 48])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's visualize an image."
      ],
      "metadata": {
        "id": "4bw5HNZeQ7Gc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_img_idx = 30 # Write any random index (between 0 and 59999)\n",
        "\n",
        "image = train_dataset[random_img_idx][0]  # 0 for image part in (image, label) tuple.\n",
        "label = train_dataset[random_img_idx][1]  # 1 for label part\n",
        "\n",
        "print(\"The image label:\", label.item(), mapping[label.item()])\n",
        "\n",
        "plt.imshow(image.reshape(image.shape[1], image.shape[1]), cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "kXxCJ5pQQ5jw",
        "outputId": "5c96aad1-ca25-4613-fead-657b1e013952"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image label: 5 ta\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7b98d01af970>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions:\n",
        "\n",
        "- Create a Neural Network: Use either PyTorch or NumPy to construct your neural network (NN).\n",
        "- Train the Model: Once the network is defined, proceed to train the model with the data.\n",
        "- Experiment with Layers: Adjust and experiment with different layer configurations to optimize the model's performance. Aim to achieve at least 80% accuracy on the validation dataset. Make sure to include a minimum of three distinct layers.\n",
        "- Explore Activation Functions: Try out various activation functions to find the most effective combination for your network."
      ],
      "metadata": {
        "id": "qvysz1ZnSh7f"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5G7ib-G0LTC1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}